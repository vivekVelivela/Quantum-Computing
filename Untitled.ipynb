{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the step-size parameters of Simultaneous Perturbation Stochastic Approximation (SPSA) in Self-Guided Quantum tomography (SGQT) simulation to prove the optimal values of alpha and gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    By vivek velivela\n",
    "\n",
    "                             University of Technology Sydney, 2019\n",
    "\n",
    "The following demonstration explains about the effect on fidelity score of Self-Guided Quantum Tomography simulation (SGQT) by the variation of gradient step size parameter ‘t’. the following Simulated on Jupyter notebook and Google Colaboratory based on their respective processing power and the following simulated indirectly on the baseline model the SGQT simulation as presented in Christopher Ferrie’s ‘Self-Guided Quantum Tomography’ paper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum tomography is a process of assigning a quantum state to mechanical descripted physical state [1]. Quantum Tomography is vital tool in Quantum information processing, depicting quantum states [3]. Quantum tomography this process needs a bit of huge qubits processing which exponentially increases, Different techniques are introduced based on the procedures they work on namely Hedged Maximum Likelihood Estimation (HMLE) and Maximum Likelihood Estimation, adaptive quantum tomography, self-guided quantum tomography and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article 1\n",
    "\n",
    "## 1.\tChristopher Ferrie ‘Self-Guided Quantum Tomography’ 2014\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-Guided Quantum tomography is a self-learning technique which is used identify quantum state where the experiment itself is guided to it’s own state [1].\n",
    " \n",
    "Unlike all other method this procedure guides itself to a true state which has its own advantages over other techniques.\n",
    "\n",
    "The main method of this research paper is to explain about the efficiency and working of SGQT via proposing an iterative algorithm to propose new states. This algorithm is based on stochastic approximation technique namely simultaneous perturbation stochastic approximation (SPSA) which allows SGQT to propose only two states which can indirectly provide the path to true state, which proves this technique is efficient [1]. As the core of the algorithm is a stochastic approach the measurements at each iteration are randomly selected which is computationally efficient [2].\n",
    "\n",
    "Each iteration of the proposed algorithm contains generating random direction to search in defined by ( deltak ), calculating estimated gradient and calculating next iteration [1]. Through iteration SGQT learns the quantum state through maximising the expectation value of a projection measurement [2].\n",
    "\n",
    "This article was written by Christopher Ferrie. He also developed Self-Guided Quantum Tomography [5]. he is senior lecture, author and a researcher at UTS: Centre for Quantum Software and Information [5].\n",
    "\n",
    "We understand that Self guided Quantum tomography is quiet efficient as it converges to true stet itself and stochastic approach is used in this algorithm which the randomness in this approach reduces the bias in selecting the measurements at each iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\tR. J. Chapman, C. Ferrie, A. Peruzzo ‘Experimental Demonstration of Self- Guided Quantum Tomography’ 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conventional techniques of quantum state identification like Standard quantum tomography (SQT) and adaptive quantum tomography (AQT) has their own disadvantages compared to SGQT. huge computational costs and data post-processing limits them to process no more than a few qubits. Sensitivity of their measurements to statistical noise makes unreliable. Measurements in quantum systems\n",
    " \n",
    "are non-deterministic hence it makes SQT a forever statistical problem [3]\n",
    "\n",
    "SGQT avoids many of the measurement errors of AQT and SQT [2]. The performance of SGQT is independent on the number of experiments which makes it superior efficient to both the other techniques [1].\n",
    "\n",
    "The main method of this research is to demonstrate the SGQT robustness and performance through a several one and two qubit experiments under different conditions which proves that SGQT has high fidelity with the projection of more than 28 photons, per 10 iterations and usage of\n",
    "~280photons [2]. At the end this article concludes that SGQT is still expensive in terms of number of measurements, but it will also open pathways to deploying many quantum tomographic tools with dimensions where SQT will be impractical.\n",
    "\n",
    "This article is written by Robert J. Chapman who is postdoctoral researcher at university of Innsbruck [6], Alberto Peruzzo is VC Senior Research Fellow in RMIT university\n",
    "[7] and Christopher Ferrie who is a researcher at UTS: Centre for Quantum Software and Information[5].\n",
    "\n",
    "The values, results and the proofs produced in this article indirectly conveys that this experiment was conducted in a lab environment\n",
    " \n",
    "which avoids the unintentional errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   3.F. Husza\tand N. M. T. Houlsby ‘Adaptive Bayesian quantum tomography ’ 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This research paper explains about the solution for statistical and optimal design problem of Quantum state tomography via proposing algorithmic framework called adaptive Bayesian quantum tomography ( ABQT ) and by developing an adaptive statistical framework based on Bayesian inference\tand\tShannon’s information.\n",
    "\n",
    "F. Husza ́r and N. M. T. Houlsby have assessed the performance of the adaptive algorithm in Monte Carlo ( MC ) simulations of qubit systems which sows the reduction in number of measurements for full tomography of two qubit states [3]. The authors also considered the information gain, which is used to define an adaptive protocol in one- and two-qubit optical experiments [11].\n",
    "\n",
    "Assessing the performance of algorithm in MC simulations is done by developing an fast sequential importance sampling (SIS) algorithm, with O(1) likelihood evaluation cost [3].\n",
    "\n",
    "F. Husza ́r is a machine learning researcher in twitter and he is a alumni of Cambridge university[9]\n",
    " \n",
    "and N. M. T. Houlsby is a Research Scientist working on machine learning in google brain team and he is PhD in Cambridge university [9].\n",
    "\n",
    "The experiments presented in this research paper are done with required configuration of apparatus which improves the accuracy of the result and reduces the bias.\n",
    "\n",
    "Although the algorithm demonstrated in this article is a huge advancement in terms in empirical performance but it does not resolve the curse of dimensionality due to the increase in the parameters with the number of qubits[3].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Robin Blume-Kohout ‘Hedged Maximum Likelihood Estimation ’ 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Likelihood Estimation ( MLE ) is a probability protocol to maximise the likelihood function, this protocol is used in estimating or reconstructing the quantum state.\n",
    "However MLE has its own drawbacks of reporting rank deficient estimates with zero eigenvalues, it means for predictive purposes this zero eigenvalue problem is disastrous [13]. There are some research papers ( refer to [12] ) which questions the admissibility of mean squared error, fidelity and relative entropy produced by MLE. Christopher Ferrie and Robin\n",
    "Blume-Kohout have also proved that the hedged estimator outperforms constrained least-squares along the Z axis.[12]\n",
    " \n",
    "The main method of this research paper is to tackle the problem of MLE via proposing a model which can be considered modified MLE called Hedged maximum likelihood estimation ( HMLE ). Where the modification majorly lies in Replacing “ standard likelihood function\tL( ρ ) = Pr (observed data | ρ) with the product of L( ρ ) and a “hedging function” [4]. Real time application have been provided by Robin Blume-Kohout that how disastrous using MLE would turn in case of data compression and gambling.\n",
    "\n",
    "The author of this paper is Robin Blume-Kohout who is a principal member of technical staff at Sandia national laboratories [10]. and this paper is published by perimeter institute of theoretical physics.\n",
    "\n",
    "We can understand that HMLE is an improved MLE protocol which covers the loop holes of MLE. hedging in HMLE is a simple solution for zero eigenvalue problem. This article conveys that HMLE produces precise results in gambling and data compression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simultaneous Perturbation Stochastic Approximation (SPSA) Backdrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPSA is the stochastic optimization technique which is the core of the algorithm. The algorithm implements the following for SPSA\n",
    "\n",
    "![1.png](1.png)---------------(1)\n",
    "\n",
    "\n",
    "The function f provides the estimates between true states and estimated states (ρ,σ).The algorithm must also predict the gradient descent stochastically to find the best estimates by the following equation\n",
    "\n",
    "![2.png](2.png) -------------(2)\n",
    "\n",
    "g is the local gradient with respect to the measured estimates at kth iteration. ∆_k is the direction chosen stochastically where β_k is the gradient step size.\n",
    "\n",
    "This gradient is used to get to the position of σ_k. In (2) two distances are being measured with respect to the product of  β_k and ∆_k with σ_k as a mid-point. Here the next step is determined by the following equation\n",
    "\n",
    "![3.png](3.png) -------------(3)\n",
    "\n",
    "From the above Equation we can consider α_k and β_k as step sizes except β_k deals with the step size of the gradient. Where difference can be observed in the steps sizes if the variables are changed\n",
    "![4.png](4.png) ----------------(4)\n",
    "\n",
    "![5.png](5.png) -----------(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We can imagine a map of all these equations as stated following\n",
    "     \n",
    "![whole.png](whole.png)\n",
    "                     \n",
    "               \n",
    "                           \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "In Chris Ferrie’s paper t = 0.101 and s = 0.602 are considered as optimal values. This paper explores different values of t and s independently which is presented as gamma and alpha in the code given by Chris Ferrie.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable naming conventions in the code and the paper goes as per the following\n",
    "‘n_sim’ -The number of simulations to calculate the average fidelity over: 100 \n",
    "\n",
    "‘Iters’ -The number of iterations per simulation: 10000.\n",
    "\n",
    " ‘Ns’ -The number of distance measure experiments per iteration: 1000 \n",
    "\n",
    "‘g_0’ -The value of a: 1 \n",
    "\n",
    "‘delta_0’ -The value of b: 0.1 \n",
    "\n",
    "‘gamma’ -The value of t: 0.101 while alpha was altered.\n",
    "\n",
    "‘alpha’- The value of s:0.602 while gamma was altered.\n",
    "\n",
    "‘A’ -The value of A: 0\n",
    "\n",
    "\n",
    "The alterations of alpha and gamma has been made on the range of \n",
    "(optimalvalue-2 , optimal value+3).\n",
    "\n",
    "Gamma Alteration\n",
    "\n",
    "We have examined the results of infidelity vs iterations by changing gamma values from (-0.099, 0.401) with various starting and ending points as mentioned below\n",
    "\n",
    "\n",
    " (-0.099, 0.301) ----(fig 1), \n",
    " (0.001, 0.401) ----(fig 2),  \n",
    " (0.001, 0.201) ----(fig 3),\n",
    " (0.101, 0.301) ----(fig 4),\n",
    "\n",
    "These simulations are done using method named \n",
    "alter_gamma(a1, a2, [steps=5])\n",
    "\n",
    "'alter_gamma' was the method created in        for this examination. The steps of this method are mentioned in 'Procedure steps'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Alteration \n",
    "\n",
    "We have examined the results of infidelity vs iterations by changing alpha values from (0.402,0.902) with various starting and ending points as mentioned below\n",
    "\n",
    " (0.402, 0.802) ----(fig 5),\n",
    " (0.502, 0.902) ----(fig 6),\n",
    " (0.502, 0.702) ----(fig 7),\n",
    " (0.602, 0.802) ----(fig 8),\n",
    "\n",
    "These simulations are done using method named \n",
    "alter_alpha(a1, a2, [steps=5])\n",
    "\n",
    "alter_alpha was the method created in for this examination. The steps of this method are mentioned in Procedure steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure steps according to the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simulating over the different values of alpha and gamma. depending on the parameter.\n",
    "\n",
    "1.1. Performing n_sim simulations to average over \n",
    "\n",
    "1.1.1. Creating a random target psi.\n",
    "\n",
    "1.1.2. Creating a starting point at the origin \n",
    "\n",
    "1.1.3. Iterating on the simulation iters times \n",
    "\n",
    "1.1.3.1. Applying the SPSA algorithm to   get σ_k+1 by changing the parameters accordingly in method named spsa()\n",
    "\n",
    "\n",
    "The highlighted line is the mean of the number of simulations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS\n",
    "\n",
    "### Results by altering gamma values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ![fig1.png](fig1.png)\n",
    " (Initial case) Fig 1: Gamma values [-0.099-0.301]\n",
    "Based on Fig4 values below 0.101 can be ignored partially.\n",
    "\n",
    "![fig2.png](fig2.png)\n",
    " \n",
    "  Fig 2: Gamma values [0.001-0.401]\n",
    "Values below 0.101 has a bit deviation at end\n",
    "\n",
    " ![fig3.png](fig3.png)\n",
    "  Fig 3: Gamma values [0.001-0.201]\n",
    "Based on Fig 2 the close values to 0.101 the similar the error rate is. \n",
    "\n",
    " ![fig4.png](fig4.png)\n",
    "  Fig 4: Gamma values [0.101-0.301]\n",
    "              Where the results are almost similar\n",
    "\n",
    "\n",
    "### Results by altering alpha values\n",
    "\n",
    "  ![fig5.png](fig5.png)\n",
    "(Initial Case) Fig 5: Alpha values [0.402-0.902]\n",
    "\n",
    "\n",
    "  ![fig6.png](fig6.png)\n",
    "            Fig 6: Alpha values [0.502-0.802]\n",
    "       Based on initial case alpha < 0.902\n",
    " \n",
    "  ![fig7.png](fig7.png)\n",
    "          Fig 7: Alpha values [0.402-0.602] based on Fig-6 comparing values -2 to 0.602\n",
    "\n",
    "  ![fig8.png](fig8.png)\n",
    "\n",
    "          Fig 8: Alpha values [0.602-0.902]. comparing the values from0.602 to +3.\n",
    "\n",
    "### Results after swapping  values of alpha and gamma\n",
    "\n",
    "   ![fig9.png](fig9.png)\n",
    " \n",
    "Fig-9:  Assigning alpha values to alter_gamma function\n",
    "   ![fig10.png](fig10.png)\n",
    " \n",
    "Fig-10:  Assigning gamma values to alter_alpha function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCUSSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are obtained by simulations done on methods by changing the parameters accordingly\n",
    "\n",
    "\tInitial values of alpha and gamma were chosen based on the range of (-2,3) optimal values depending on the parameter selected.\n",
    "The whole procedure iterates over the values in between the range for 5 times depending on span function in the code.\n",
    " EX:[4,9] were passed depending on span functions formula [4,5,6,7,8,9]\n",
    "\n",
    "\tIn this examination n_sim is 100 which relates to the execution of the algorithm.\n",
    "\n",
    "\tIn this examination a random target was selected through Haar() which was assigned to psi using a pre-defined method developed by Chris Ferrie.\n",
    "\n",
    "\tIn this Examination the   starting point was selected by a pre-defined method developed by Chris Ferrie which is from origin.\n",
    "\n",
    "\tThe value of  ‘iters’ is 10^4 which was selected on an assumption that the high the ‘iters’ value the better error rate can be obtained.\n",
    "\n",
    "\tSPASA algorithm was implemented here in this step where the parameters are as followed for alpha and gamma respectively.\n",
    "\n",
    "\n",
    "Spsa (idy , psi, x_0, N =  Ns, g_0 = 1, delta_0 = 1e-1, alpha = a_range[idN])\n",
    "\n",
    "spsa (idy , psi, x_0, N =  Ns, g_0 = 1, delta_0 = 1e-1, gamma = a_range[idN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition on Results of Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Initial values that were considered are values among [-0.099-0.301] (Fig-3). the reason for selecting these values as Initial ones is these contains all the bracket values of the given optimal value in            C. Ferrie’s paper.\n",
    "Observed in the Initial case it can be seen that even though gamma = 0.101, the performance was almost equal with the remaining values until (le2.5) where the error rate got tipped of to the high level. Where as the remaining values ended up almost at same spot at (le4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on the deviation of least gamma value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huge deviation of -0.099 can be explained mathematically by following steps.\n",
    "\n",
    "1.\tFor instance round off  -0.099 to  -1\n",
    "\n",
    "2.\tSubstitute -1 in Eq(4) in place of t. as gamma = t by Chris Ferries code. \n",
    "\n",
    "3.\tResulted value will be  equal to b(k+1) which will be very big value compared to the output of any other substituted values in the graph.Which affects in the error rate.\n",
    "\n",
    "4.\tThis is one of the reason for the deviation in the error form a certain instance in the graph.\n",
    "\n",
    "5.\tIt is assumed that As alpha is a exponent of an expression in the denominator the values for alpha must not be negative (Fig-1) and not too high i.e not greater than 0.527 (Fig-9).\n",
    "\n",
    "6.\tThe output is based on all the parameters present in the expression, thus alpha is just one of them which plays a major role in the rate of change of the output.\n",
    "\n",
    "To ensure that behavior of gamma doesn’t go in same way as before in the case of -0.009 this time the next two simulation(Fig 2 and 3) were done with positive values with same starting point and different ending values.\n",
    "\n",
    "It can be observed that both of the graphs are similar even though their ending points were different. Where 0.101 was a bit deviated from converging to minimal error to a bit high error rate at end of (le4) iterations. And in (fig-2) 0.401at the end had a bit fluctuated but converged to a point with others.\n",
    "\n",
    "As we got to know that deviation occurs with two values we now have simulated from the optimal value [0.101-0.301] where all the values have the same kind of behavior seems to be converged at a point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuitions on Alpha Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial values of alpha were taken because it contains the extreme values of mentioned range with optimal value in the middle.\n",
    "From Fig-5 we can say that alpha must be <0.902, whereas 0.777 has lowest error rate at (le4) although it has highest from the start. And 0.402 is quite contrary to 0.777.\n",
    "\n",
    "Based on the initial case we ensure next two simulations are done to find the new value which has better results than 0.902\n",
    "From Fig-6 and 7 we can observe that other than optimal value 0.802 and 0.727 shows similar result like optimal value.\n",
    "\n",
    "As observed in Fig-8 we have simulated from optimal value to 0.902 to observe the rate of deviation from the optimal value to the extreme value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation on the deviation of high alpha value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Deviation of the 0.902 can be explained mathematically by following steps\n",
    "\n",
    "1.\tFor Instance, round off 0.902 to 1\n",
    "\n",
    "2.\tSubstitute alpha value i.e 1 in Eq 5 in place of s as per given by Chris Ferries code.\n",
    "\n",
    "3.\tResulted value will be a/(K+1+A)\n",
    "      Which is a huge value compared to the output resulted by substitution of other value in the graph.\n",
    "\n",
    "4.\tThis is one of the reason for the deviation in the error from a certain instance in the graph.\n",
    "\n",
    "5.\tIt is assumed that As gamma is a exponent of an expression in the denominator the values for gamma must not be negative  (Fig-10) and not be high.(Fig-8)\n",
    "\n",
    "6.\tThe output is based on all the parameters present in the expression, thus alpha is just one of them and plays a major role in the rate of change of the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although adaptive Quantum tomography is a also a dynamic but it has its own disadvantages in case of computational and robustness over Self-guided Quantum Tomography. Out of all the method of advancements and their drawbacks mentioned above from all the articles Self-guided Quantum tomography proposed by Dr Christopher Ferrie is the most dynamic method and is robust to most of the common quantum tomographic problems. Although adaptive Quantum tomography is a also a dynamic but it has its own disadvantages in case of computational and robustness over Self-guided Quantum.\n",
    "As per presented results the best optimal values for alpha and gamma for le4 iteration will be close to the actual optimal values but may not be the same \n",
    "optimal value for alpha with (le4) : 0.552(Acc to Fig-7). As observed in the graph 0.602 has a least error rate at the end but until the instance of (le2.3) 0.552 has a better performance compared to 0.602.\n",
    "Optimal value for gamma with (le4): As observed in Fig-4, 0.251 has a better performance although it emerges with other values around (le2).     \n",
    "As the optimal values given by chris ferrie are based on the number of simulations which is (le5) and the optimal values presented above are done on (le4) iterations.    Considering the time consumed for some of the iteration values (le4) has been chosen to perform All the simulations. Chris Ferrie had  performed simulations with (le5) iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]\tC. Ferrie (2014) ‘Self-Guided Quantum Tomography’, Physical Review Letters 113(19), Centre for Quantum Information and Control, University of New Mexico,\n",
    "Albuquerque\n",
    "\n",
    "[2]\tR. J. Chapman, C. Ferrie A. Peruzzo (2016) ‘Experimental Demonstration of Self- Guided Quantum Tomography’ Physical Review Letters, 117(4)\n",
    "\n",
    "[3]\tF. Huszár N. M. T. Houlsby (2012) ‘Adaptive Bayesian quantum tomography'\n",
    "\n",
    "[4]\tRobin Blume-Kohout (2010) ‘Hedged Maximum Likelihood Estimation ’\n",
    "\n",
    "[5]\t‘Christopher Ferrie - University of Technology Sydney’ (https://csferrie.com/academic/), viewed 10 April 2019\n",
    "\n",
    "[6]\tRobert J - ‘university of Innsbruck’(https://www.linkedin.com/in/ro bert-j-chapman- 46234849/?originalSubdomain=au)\n",
    " \n",
    "[10]\tRobin Blume-Kohout-‘ Sandia national laboratories’(https://www.linkedin.com/in/ robin-blume-kohout-8861286/)\n",
    "\n",
    "[11]\tChristopher Granade , Christopher Ferrie and Steven T Flammia (2017) ‘Practical adaptive quantum tomography’\n",
    "\n",
    "[12]\tChristopher Ferrie, Robin Blume- Kohout (2018) ‘Maximum likelihood quantum state tomography is inadmissible’.\n",
    "\n",
    "[13]\tRobin Blume-Kohout (2010) ‘Optimal, reliable estimation of quantum states’\n",
    "\n",
    "\n",
    "[14]\tS. S. Straupe (2016) ‘Adaptive Quantum Tomography’.\n",
    "\n",
    "[15]\tJ. Rˇ eha ́cˇek, Z. Hradil, and M. Jezˇek (2001) ‘Iterative algorithm for reconstruction of entangled states’\n",
    "\n",
    "[16]\tJohn A. Smolin, Jay M. Gambetta, and Graeme Smith (2012)’ Efficient Method for Computing the Maximum- Likelihood Quantum State from Measurements with Additive Gaussian Noise ’\n",
    " \n",
    "\n",
    "[7]\tAlberto Peruzzo-‘RMIT University’(https://www.rmit.edu.au/conta ct/staff-contacts/academic-staff/p/peruzzo- dr-alberto)\n",
    "\n",
    "[8]\tF. Husza ́r - ‘Cambridge University’(https://twitter.com/fhuszar?lan g=en)\n",
    "\n",
    "[9]\tN.M.T.Houlsby-‘ Cambridge University’(https://ai.google/research/peop le/NeilHoulsby)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
